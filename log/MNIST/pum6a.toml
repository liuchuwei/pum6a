seed = 8

[dataload]

    dataset = "MNIST"
    num_bag = 500
    mean_nbag_length = 10
    var_nbag_length = 2
    confactor = 0.3
    target = 9
    seed = 8

[model]

    model_chosen = 'pum6a' # pum6a, puma, iAE, puIF, RF, PU-SKC, puMIL, LSDD.toml, DSDD
    device = 'cuda'

    [model.feature_extractor]
    type = 'conv'
    hidden_neurons = [20, 50]
    linear_input = 800
    hidden_activation = 'relu'
    kernal_size = 5
    pool_kernal_size = 2
    pool_stride = 2

    [model.classifier]
    input = 2

    [model.attention]
    L=500  # Attention model_factory input nodes
    D=128  # Attention model_factory intermediate nodes
    K=1  # Attention model_factory output nodes

[trainer]

    trainer_chosen='adanTrainer' # adanTrainer, puIF_Trainer, RF_Trainer, Trainer
    device = 'cuda'
    n_splits = 5    # 5-fold-cross-validataion
    save_dir = 'result/MNIST/pum6a/50'
    seed = 8

    epochs = 300 # 100, 1000
    batch_size = 16
    freq = 0.5  # 50% freqency
    early_stopping = 3
    verbose = true

    [trainer.optimizer]

    opt = 'AdamW'
    lr = 0.0005
    weight_decay=1e-05
    amsgrad=true
    opt_scheduler='none'