dataset = "MNIST"
device = "cuda"
seed = 88888888
#seed = 555
epochs = 1000
batch_size=16
confactor='False'
model_chosen='pum6a'

[optimizer]

    opt = 'AdamW'
    lr = 0.0005
    weight_decay=1e-05
    amsgrad='True'
    opt_scheduler='none'

[model]
    device = "cuda"

    [model.feature_extractor]
    type = 'conv'
    kernal_size = 5
    pool_kernal_size = 2
    pool_stride = 2
    hidden_neurons = [20, 50]
    hidden_activation = 'relu'
    linear_input = 800 # 50 * 4 * 4

    [model.attention]
    L=500  # Attention model input nodes
    D=128  # Attention model intermediate nodes
    K=1    # Attention model output nodes

