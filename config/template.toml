seed = 88888888


[dataload]

    dataset = "Annthyroid"
    num_bag = 500
    mean_nbag_length = 10
    var_nbag_length = 2
    mean_abag_length = 4
    var_abag_length = 1
    confactor = 0.3
    target = 1
    seed = 8888888


[model]

    model_chosen = 'pum6a'
    device = 'cuda'

#    [model.feature_extractor]
#    type = 'conv'
#    kernal_size = 5
#    pool_kernal_size = 2
#    pool_stride = 2
#    hidden_neurons = [20, 50]
#    hidden_activation = 'relu'
#    linear_input = 800 # 50 * 4 * 4

    [model.feature_extractor]
    type = 'linear'
    n_features = 6
    dropout_rate = 0
    hidden_neurons = [4, 2]
    batch_norm = 'True'
    hidden_activation = 'relu'

#    [model.attention]
#    L=500  # Attention model_factory input nodes
#    D=128  # Attention model_factory intermediate nodes
#    K=1    # Attention model_factory output nodes

    [model.attention]
    L=2  # Attention model_factory input nodes
    D=1  # Attention model_factory intermediate nodes
    K=1    # Attention model_factory output nodes


[trainer]

    trainer_chosen='adanTrainer'
    device = 'cuda'
    n_splits = 5    # 5-fold-cross-validataion
    save_dir = 'result/Annthyroid'
    seed = 8888888

    epochs = 300
    batch_size = 16
    n_pos = 80  # 400/80*100%=5%
    early_stopping = 3

    [trainer.optimizer]

    opt = 'AdamW'
    lr = 0.0005
    weight_decay=1e-05
    amsgrad='True'
    opt_scheduler='none'

